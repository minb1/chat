# logius/models.py
import uuid
from django.db import models
# Use ArrayField if using PostgreSQL and want native array type
# from django.contrib.postgres.fields import ArrayField

# ------------------------
# Document Model
# ------------------------
class Document(models.Model):
    """Represents a chunk of text content from a source document."""
    # Use UUIDField if your primary key is UUID, otherwise AutoField is default
    # id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    file_path = models.TextField(unique=True, db_index=True, help_text="Unique identifier path for the document chunk")
    doc_tag = models.TextField(blank=True, null=True, help_text="Optional tag or category for the document")
    content = models.TextField(help_text="The actual text content of the chunk")
    original_url = models.URLField(max_length=500, blank=True, null=True, help_text="Main source URL for the document")
    chunk_url = models.URLField(max_length=500, blank=True, null=True, help_text="Permalink to the specific document chunk")
    inserted_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        indexes = [
            models.Index(fields=['doc_tag'], name='idx_documents_doc_tag'),
            models.Index(fields=['file_path'], name='idx_documents_file_path'), # Index for faster lookups
        ]
        ordering = ['-inserted_at'] # Default ordering

    def __str__(self):
        # Provides a human-readable representation of the object
        return f"{self.doc_tag or 'No Tag'}: {self.file_path}"

# ------------------------
# ChatQuery Model
# ------------------------
class ChatQuery(models.Model):
    """Stores information about a single user query and the generated response within a chat session."""
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False, help_text="Unique identifier for this query turn")
    chat_id = models.CharField(max_length=36, db_index=True, help_text="Session ID for grouping queries belonging to the same conversation")
    user_query = models.TextField(help_text="Original user query text")

    # --- Conversational RAG Fields ---
    rewritten_query = models.TextField(blank=True, null=True, help_text="Standalone query generated by CQR (Contextual Query Rewriting)")
    # Using JSONField for embedding storage for broader DB compatibility.
    # Replace with ArrayField(models.FloatField(),...) if using PostgreSQL specifically.
    rewritten_query_embedding = models.JSONField(blank=True, null=True, help_text="Embedding vector of the rewritten query (stored as list)")
    final_doc_ids = models.JSONField(
        default=list,
        help_text="List of Qdrant point IDs of the final documents used for context in this turn, potentially becoming sticky memory for the next."
    )
    # --- End Conversational RAG Fields ---

    llm_response = models.TextField(blank=True, null=True, help_text="Response generated by the LLM")
    doc_tag = models.JSONField(
        default=list,
        blank=True,
        help_text="List of document tags associated with the final context documents used for this response"
    )
    # Removed file_paths as final_doc_ids serves a similar purpose for tracking context documents
    # file_paths = models.JSONField( default=list, help_text="List of file_path strings for retrieved document chunks")
    model_used = models.CharField(max_length=100, blank=True, help_text="Identifier of the LLM model used for generation")
    created_at = models.DateTimeField(auto_now_add=True, db_index=True)

    class Meta:
        indexes = [
            # Compound index for efficient lookup of the latest turn in a chat
            models.Index(fields=['chat_id', '-created_at'], name='chatquery_chat_id_created_idx'), # Renamed to fit 30 chars            # Keep other indexes if specific queries benefit from them
            # models.Index(fields=['doc_tag'], name='idx_chatquery_doc_tag'), # Indexing JSONField might depend on DB
            # models.Index(fields=['created_at'], name='idx_chatquery_created_at'), # Covered by compound index
        ]
        # Order by creation time descending to easily get the latest turn
        ordering = ['-created_at']

    def __str__(self):
        # Provides a human-readable representation of the object
        return f"Query {self.id} in Chat {self.chat_id} at {self.created_at.strftime('%Y-%m-%d %H:%M')}"

# ------------------------
# Feedback Model
# ------------------------
class Feedback(models.Model):
    """Stores user feedback on a specific LLM response."""
    FEEDBACK_CHOICES = [
        ('helpful', 'Helpful'),
        ('unhelpful', 'Unhelpful'),
        ('false', 'False/Incorrect'),
        # Add more choices as needed
    ]
    query = models.ForeignKey(
        'ChatQuery',
        related_name='feedbacks', # Allows accessing feedback from ChatQuery object: query.feedbacks.all()
        on_delete=models.CASCADE, # Delete feedback if the associated query is deleted
        help_text="The specific query this feedback refers to"
    )
    feedback_type = models.CharField(
        max_length=20,
        choices=FEEDBACK_CHOICES,
        help_text="The type of feedback provided"
    )
    feedback_text = models.TextField(
        blank=True,
        null=True,
        help_text="Optional free-text comments from the user if implemented"
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        ordering = ['-created_at'] # Show most recent feedback first

    def __str__(self):
        # Provides a human-readable representation of the object
        return f"Feedback ({self.get_feedback_type_display()}) for Query {self.query.id}"
